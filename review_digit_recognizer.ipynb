{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras import losses, metrics, optimizers, initializers, regularizers\n",
    "\n",
    "np.random.seed(42)\n",
    "import pickle\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('train.csv')\n",
    "train_raw = train_raw.copy()\n",
    "test_X_raw = pd.read_csv('test.csv')\n",
    "test_X_raw = test_X_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_raw = train_raw[train_raw.columns[1:]]\n",
    "train_Y_raw = train_raw['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = pd.concat([train_X_raw, test_X_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_raw shape: (42000, 784)\n",
      "test_X_raw shape: (28000, 784)\n",
      "X_raw shape: (70000, 784)\n",
      "train_X_raw.shape[0] + test_X_raw.shape[0] = 70000\n"
     ]
    }
   ],
   "source": [
    "print('train_X_raw shape:', train_X_raw.shape)\n",
    "print('test_X_raw shape:', test_X_raw.shape)\n",
    "print('X_raw shape:', X_raw.shape)\n",
    "print('train_X_raw.shape[0] + test_X_raw.shape[0] =', train_X_raw.shape[0] + test_X_raw.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at Y value distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4132\n",
       "1    4684\n",
       "2    4177\n",
       "3    4351\n",
       "4    4072\n",
       "5    3795\n",
       "6    4137\n",
       "7    4401\n",
       "8    4063\n",
       "9    4188\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y_raw.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    784\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw.isnull().sum().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y value one hot transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_Y_pre_transform = train_Y_raw.copy()\n",
    "train_Y_pre_split = OneHotEncoder(sparse=False).fit_transform(train_Y_pre_transform.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    4\n",
       "4    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y_pre_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X value transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pre_transform = X_raw.copy()\n",
    "X = np.divide(X_pre_transform, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X value reshape\n",
    "# according to the description file for the dataset\n",
    "# reshape image in 3 dimensions (height=28px, width=28px , channel=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a365cfd50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAN0UlEQVR4nO3df4wc9XnH8c8H+zBgoPIP7DjgYodSUdqqJlxNKFVLhYiMVWqQCsWqIhehOm1BBYlKRaQSVM0fVpUfSqskkgNWnJQaIQECJajgWEguaeNwJg62YwiEOGDs+kAOwVBizr6nf9y4Oszt7Hpndmft5/2STrs7z87Mc6v73Ozud3a/jggBOPmd0nQDAPqDsANJEHYgCcIOJEHYgSSm93Nnp3pGnKaZ/dwlkMov9a7ej0OeqlYp7LaXSfqSpGmS7ouINWX3P00zdZmvqrJLACW2xKaWta6fxtueJunLkq6RdLGklbYv7nZ7AHqrymv2pZJejohXIuJ9SQ9KWlFPWwDqViXs50p6bdLtPcWyD7C92vaI7ZExHaqwOwBVVAn7VG8CfOjc24hYGxHDETE8pBkVdgegiiph3yNp4aTb50naW60dAL1SJezPSrrQ9mLbp0q6SdLj9bQFoG5dD71FxGHbt0l6UhNDb+siYmdtnQGoVaVx9oh4QtITNfUCoIc4XRZIgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkKs3iinp85pVtpfU1H//D0vqRt35RZzsnjSU/aF17ct3vla47/1//q+Zumlcp7LZ3Szoo6YikwxExXEdTAOpXx5H9jyLizRq2A6CHeM0OJFE17CHpKdtbba+e6g62V9sesT0ypkMVdwegW1Wfxl8REXttz5O00fYLEbF58h0iYq2ktZJ0tmdHxf0B6FKlI3tE7C0uRyU9KmlpHU0BqF/XYbc90/ZZR69L+qSkHXU1BqBeVZ7Gz5f0qO2j2/n3iPiPWro6yfzyj8uf8Hxs+jOl9Z/83cWl9UX/8N/H3VMGn523tWXtSZWPs5+Mug57RLwi6Xdq7AVADzH0BiRB2IEkCDuQBGEHkiDsQBJ8xLUPTrl9f2n9nGkz+tTJyeXN1Ze3uUfrobeMOLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs9dg2q8tLq3fvmhjpe3P2sUX/Ezlpr99qukWTigc2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZa/DWpfNL69ec8fNK2/+VB75Xaf0TVVxe/uXFK876Smn9+4dOb1lbsO6HpeuOl1ZPTBzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtn74JQ2/1OvffFP2mzh9fqaOYGM/u7M0vri6aeV1v98+00ta7Pf/XFXPZ3I2h7Zba+zPWp7x6Rls21vtP1ScTmrt20CqKqTp/Ffl7TsmGV3SdoUERdK2lTcBjDA2oY9IjZLOnDM4hWS1hfX10u6rua+ANSs2zfo5kfEPkkqLue1uqPt1bZHbI+M6VCXuwNQVc/fjY+ItRExHBHDQ2ICQ6Ap3YZ9v+0FklRcjtbXEoBe6Dbsj0taVVxfJemxetoB0Cttx9ltb5B0paS5tvdIukfSGkkP2b5F0quSbuhlk4Nu39WHS+vjbT4dPe3m8v+55VvPq93j+v535pZU842ztw17RKxsUbqq5l4A9BCnywJJEHYgCcIOJEHYgSQIO5AEH3Ht0LQ5s1vWVl76/T52ksesa6t9tHfODk7PnowjO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTh7h8YuPr9l7Z55T/axkzyumv9ipfWHvrO1pk5ODhzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtk79NO/6t22X7jj3NL6Rzd/tLQ+emnr/9kXbDh2mr4POrKz2lh2Fbs/e3lp/cFZn2+zhaH6mkmAIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4e4dOP6P1d5CfUvF/5gs3frm0PvRn00rrY3GkdfHmbjrq3EUP3Vpan/la68fmn258oHTdM0+Z0VVPR00/f2HL2uGfvVZp2yeitn+lttfZHrW9Y9Kye22/bntb8bO8t20CqKqTQ9LXJS2bYvkXI2JJ8fNEvW0BqFvbsEfEZknl51wCGHhVXmzeZvv54mn+rFZ3sr3a9ojtkTEx9xbQlG7D/lVJF0haImmfpJafWIiItRExHBHDQ6r2hguA7nUV9ojYHxFHImJc0tckLa23LQB16yrsthdMunm9pB2t7gtgMLQdZ7e9QdKVkuba3iPpHklX2l4iKSTtlvTpHvY4ECLcsjau8Z7ueyzK673ef5l25whU6a3qb3Xff25oWbt6pPxP9ozHzi6tz3mk/Pg2fvBgab0JbcMeESunWHx/D3oB0EOcLgskQdiBJAg7kARhB5Ig7EASfMS1Q7P+7cyWtRvmXFu67idm/bS0fuec8mGc+3/xq6X1Mk+88dul9c8teri0fv70U7ved9PmTju9Ze2RS9eWrrv8vdvKt/2tE+9rrDmyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjmjz+ckane3ZcZmv6tv+BsX0j8wvrY9dsKC0PvTqm13v+/Bre0rrvuQ3S+vjZ5SPJ5d88leS9POLWo91f/cf/6V03WU/+tPS+tC9Lb8NTVJ5b9PeHStf9wc7S+uDakts0ttxYMrfnCM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTB59n74PD/7C+tu039cJ3NHKPdeHKbYfS29bf++pLj6mey0bdbf4eAJJ333W2l9bLe+nd2yeDgyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDOjkqmLz6/tL7ryvtKquXHGrcbxMdxaXtkt73Q9tO2d9neafv2Yvls2xttv1Rcln+TAIBGdfI0/rCkOyPiNyR9QtKtti+WdJekTRFxoaRNxW0AA6pt2CNiX0Q8V1w/KGmXpHMlrZC0vrjbeknX9apJANUd1xt0thdJukTSFknzI2KfNPEPQdK8Fuustj1ie2RMh6p1C6BrHYfd9pmSHpZ0R0S83el6EbE2IoYjYnhIM7rpEUANOgq77SFNBP2BiHikWLzf9oKivkDSaG9aBFCHtkNvti3pfkm7IuILk0qPS1olaU1x+VhPOsQJbVzjXa976lNn19gJOhlnv0LSpyRtt330A8R3ayLkD9m+RdKrkm7oTYsA6tA27BHxjFp/D0C+GR+AExSnywJJEHYgCcIOJEHYgSQIO5AEH3FFJf/76+f0bNtzt7/Xs21nxJEdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnB2V7L6+++PF0++VT8k8/c13SutHut5zThzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtlRyUVfaTM50LWtS3/z7ZtLV73wxe910RFa4cgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0k4IsrvYC+U9A1JH5E0LmltRHzJ9r2S/lLSG8Vd746IJ8q2dbZnx2Vm4legV7bEJr0dB6acdbmTk2oOS7ozIp6zfZakrbY3FrUvRsTn6moUQO90Mj/7Pkn7iusHbe+SdG6vGwNQr+N6zW57kaRLJG0pFt1m+3nb62zParHOatsjtkfGdKhSswC613HYbZ8p6WFJd0TE25K+KukCSUs0ceT//FTrRcTaiBiOiOEhzaihZQDd6Cjstoc0EfQHIuIRSYqI/RFxJCLGJX1N0tLetQmgqrZht21J90vaFRFfmLR8waS7XS9pR/3tAahLJ+/GXyHpU5K2295WLLtb0krbSySFpN2SPt2TDgHUopN345+RNNW4XemYOoDBwhl0QBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJNp+lXStO7PfkPSzSYvmSnqzbw0cn0HtbVD7kuitW3X2dn5EnDNVoa9h/9DO7ZGIGG6sgRKD2tug9iXRW7f61RtP44EkCDuQRNNhX9vw/ssMam+D2pdEb93qS2+NvmYH0D9NH9kB9AlhB5JoJOy2l9l+0fbLtu9qoodWbO+2vd32NtsjDfeyzvao7R2Tls22vdH2S8XllHPsNdTbvbZfLx67bbaXN9TbQttP295le6ft24vljT52JX315XHr+2t229Mk/VjS1ZL2SHpW0sqI+FFfG2nB9m5JwxHR+AkYtv9A0juSvhERv1Us+2dJByJiTfGPclZE/P2A9HavpHeansa7mK1oweRpxiVdJ+kv1OBjV9LXjerD49bEkX2ppJcj4pWIeF/Sg5JWNNDHwIuIzZIOHLN4haT1xfX1mvhj6bsWvQ2EiNgXEc8V1w9KOjrNeKOPXUlffdFE2M+V9Nqk23s0WPO9h6SnbG+1vbrpZqYwPyL2SRN/PJLmNdzPsdpO491Px0wzPjCPXTfTn1fVRNinmkpqkMb/roiIj0u6RtKtxdNVdKajabz7ZYppxgdCt9OfV9VE2PdIWjjp9nmS9jbQx5QiYm9xOSrpUQ3eVNT7j86gW1yONtzP/xukabynmmZcA/DYNTn9eRNhf1bShbYX2z5V0k2SHm+gjw+xPbN440S2Z0r6pAZvKurHJa0qrq+S9FiDvXzAoEzj3WqacTX82DU+/XlE9P1H0nJNvCP/E0mfaaKHFn19TNIPi5+dTfcmaYMmntaNaeIZ0S2S5kjaJOml4nL2APX2TUnbJT2viWAtaKi339fES8PnJW0rfpY3/diV9NWXx43TZYEkOIMOSIKwA0kQdiAJwg4kQdiBJAg7kARhB5L4P0jWBuCOivvVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "number = 42\n",
    "plt.imshow(X[number][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, dev, test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 28, 28, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_pre_split = X[:train_X_raw.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = X[train_X_raw.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_raw shape: (42000, 784)\n",
      "train_X_pre_split shape: (42000, 28, 28, 1)\n",
      "test_X shape: (28000, 28, 28, 1)\n",
      "train_X_raw.shape[0] + test_X.shape[0] = 70000\n"
     ]
    }
   ],
   "source": [
    "print('train_X_raw shape:', train_X_raw.shape)\n",
    "print('train_X_pre_split shape:', train_X_pre_split.shape)\n",
    "print('test_X shape:', test_X.shape)\n",
    "print('train_X_raw.shape[0] + test_X.shape[0] =', train_X_pre_split.shape[0] + test_X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, dev_X, train_Y, dev_Y = train_test_split(train_X_pre_split, train_Y_pre_split, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: (31500, 28, 28, 1)\n",
      "train Y shape: (31500, 10)\n",
      "dev X shape: (10500, 28, 28, 1)\n",
      "dev Y shape: (10500, 10)\n"
     ]
    }
   ],
   "source": [
    "print('train X shape:', train_X.shape)\n",
    "print('train Y shape:', train_Y.shape)\n",
    "print('dev X shape:', dev_X.shape)\n",
    "print('dev Y shape:', dev_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cnn(train_X, train_Y, dev_X, dev_Y, \n",
    "              optimizer='Adam', kernel_initializer='he_normal', bias_initializer='he_normal', batch_size=32, epochs=50, verbose=1):\n",
    "\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    from keras.callbacks import ReduceLROnPlateau\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import (Dense, Dropout, BatchNormalization, Conv2D, MaxPool2D, Flatten)\n",
    "    from keras import losses\n",
    "    from keras import metrics\n",
    "    from keras import optimizers\n",
    "    from keras import initializers\n",
    "    from keras import regularizers\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, activation='relu', kernel_size=(3, 3), padding='Same', input_shape=(28, 28, 1), \n",
    "                     kernel_initializer=kernel_initializer, \n",
    "                     bias_initializer=bias_initializer))\n",
    "    model.add(Conv2D(64, activation='relu', kernel_size=(3, 3), padding='Same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2),strides=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(128, activation='relu', kernel_size=(3, 3), padding='Same'))\n",
    "    model.add(Conv2D(128, activation='relu', kernel_size=(3, 3), padding='Same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(256, activation='relu', kernel_size=(3, 3), padding='Same'))\n",
    "    model.add(Conv2D(256, activation='relu', kernel_size=(3, 3), padding='Same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss=losses.categorical_crossentropy, \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    image_augmentation = ImageDataGenerator(\n",
    "                        featurewise_center=False, samplewise_center=False, \n",
    "                        featurewise_std_normalization=False, samplewise_std_normalization=False, \n",
    "                        zca_whitening=False, zca_epsilon=1e-06, \n",
    "                        rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, \n",
    "                        brightness_range=None, shear_range=0.0, zoom_range=0.1, channel_shift_range=0.0, \n",
    "                        fill_mode='nearest', cval=0.0, horizontal_flip=False, vertical_flip=False)\n",
    "    \n",
    "    image_augmentation.fit(train_X)\n",
    "    \n",
    "    lr_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "    \n",
    "    \n",
    "    history = model.fit_generator(image_augmentation.flow(train_X,train_Y, batch_size=batch_size),\n",
    "                                  epochs=epochs, validation_data=(dev_X, dev_Y), \n",
    "                                  steps_per_epoch=np.ceil(train_X.shape[0]/batch_size), \n",
    "                                  verbose=verbose,\n",
    "                                  callbacks=[lr_reduction])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(history):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    print('train set loss: {:.4f}'.format(history.history['loss'][-1]))\n",
    "    print('dev set loss: {:.4f}'.format(history.history['val_loss'][-1]))\n",
    "    print('train set accuracy: {:.4f}'.format(history.history['acc'][-1]))\n",
    "    print('dev set accuracy: {:.4f}'.format(history.history['val_acc'][-1]))\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train Loss', 'Dev Loss'], loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train Accuracy', 'Dev Accuracy'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      " 3/31 [=>............................] - ETA: 6:59 - loss: 9.5768 - accuracy: 0.1012"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-1e9d2be2ac96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model, history = model_cnn(train_X, train_Y, dev_X, dev_Y, \n\u001b[1;32m      2\u001b[0m                            \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                            batch_size=1024, epochs=50)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-7505f93eb7ed>\u001b[0m in \u001b[0;36mmodel_cnn\u001b[0;34m(train_X, train_Y, dev_X, dev_Y, optimizer, kernel_initializer, bias_initializer, batch_size, epochs, verbose)\u001b[0m\n\u001b[1;32m     61\u001b[0m                                   \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                                   callbacks=[lr_reduction])\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, history = model_cnn(train_X, train_Y, dev_X, dev_Y, \n",
    "                           optimizer=optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), \n",
    "                           batch_size=1024, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv01 = pd.DataFrame(data=[test_X_raw.index.values, y01]).T\n",
    "output_csv01.columns = ['Id', 'SalePrice']\n",
    "output_csv01 = output_csv01.astype('float')\n",
    "output_csv01.to_csv('./outputs/output_csv01.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
